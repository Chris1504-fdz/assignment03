2025-12-09 03:55:46,461 | Using device: cuda
2025-12-09 03:55:46,763 | Loading tokenized datasets from disk...
2025-12-09 03:55:46,773 | Train size: 144720
2025-12-09 03:55:46,773 | Val size: 16080
2025-12-09 03:55:46,773 | Initializing reward model...
2025-12-09 03:55:47,400 | Total steps: 90450, Warmup steps: 9045
2025-12-09 03:55:47,400 | ===== Epoch 1/5 =====
2025-12-09 03:59:32,077 | [Step 200] loss = 0.9217 | acc = 0.5000 | grad_norm = 23.7437
2025-12-09 04:03:14,530 | [Step 400] loss = 0.8640 | acc = 0.5156 | grad_norm = 13.7859
2025-12-09 04:06:56,774 | [Step 600] loss = 0.8561 | acc = 0.5038 | grad_norm = 15.0080
2025-12-09 04:10:39,106 | [Step 800] loss = 0.8087 | acc = 0.4900 | grad_norm = 25.5770
2025-12-09 04:14:21,463 | [Step 1000] loss = 0.7575 | acc = 0.5006 | grad_norm = 15.9722
2025-12-09 04:18:03,830 | [Step 1200] loss = 0.7273 | acc = 0.5350 | grad_norm = 38.0482
2025-12-09 04:21:46,124 | [Step 1400] loss = 0.7239 | acc = 0.5400 | grad_norm = 14.5696
2025-12-09 04:25:28,449 | [Step 1600] loss = 0.7009 | acc = 0.5506 | grad_norm = 8.6819
2025-12-09 04:29:10,845 | [Step 1800] loss = 0.7122 | acc = 0.5194 | grad_norm = 34.7425
2025-12-09 04:32:53,258 | [Step 2000] loss = 0.7034 | acc = 0.5269 | grad_norm = 62.5862
2025-12-09 04:36:35,647 | [Step 2200] loss = 0.6954 | acc = 0.5494 | grad_norm = 8.7162
2025-12-09 04:40:18,052 | [Step 2400] loss = 0.7121 | acc = 0.5062 | grad_norm = 3.5945
2025-12-09 04:44:00,448 | [Step 2600] loss = 0.6806 | acc = 0.5575 | grad_norm = 16.6178
2025-12-09 04:47:42,733 | [Step 2800] loss = 0.6827 | acc = 0.5619 | grad_norm = 7.7190
2025-12-09 04:51:25,035 | [Step 3000] loss = 0.6825 | acc = 0.5531 | grad_norm = 10.5683
2025-12-09 04:55:07,353 | [Step 3200] loss = 0.6893 | acc = 0.5506 | grad_norm = 14.2321
2025-12-09 04:58:49,598 | [Step 3400] loss = 0.6802 | acc = 0.5600 | grad_norm = 6.0401
2025-12-09 05:02:31,880 | [Step 3600] loss = 0.6674 | acc = 0.5844 | grad_norm = 15.5166
2025-12-09 05:06:14,173 | [Step 3800] loss = 0.6799 | acc = 0.5631 | grad_norm = 13.1202
2025-12-09 05:09:56,443 | [Step 4000] loss = 0.6799 | acc = 0.5563 | grad_norm = 23.5922
2025-12-09 05:13:38,695 | [Step 4200] loss = 0.6738 | acc = 0.5725 | grad_norm = 5.1162
2025-12-09 05:17:21,016 | [Step 4400] loss = 0.6811 | acc = 0.5731 | grad_norm = 7.2238
2025-12-09 05:21:03,327 | [Step 4600] loss = 0.6655 | acc = 0.5844 | grad_norm = 20.1313
2025-12-09 05:24:45,575 | [Step 4800] loss = 0.6677 | acc = 0.5938 | grad_norm = 16.3113
2025-12-09 05:28:27,873 | [Step 5000] loss = 0.6612 | acc = 0.6069 | grad_norm = 4.0120
2025-12-09 05:32:10,220 | [Step 5200] loss = 0.6695 | acc = 0.5744 | grad_norm = 8.4577
2025-12-09 05:35:52,549 | [Step 5400] loss = 0.6524 | acc = 0.5994 | grad_norm = 3.9296
2025-12-09 05:39:34,821 | [Step 5600] loss = 0.6703 | acc = 0.5981 | grad_norm = 15.0832
2025-12-09 05:43:17,110 | [Step 5800] loss = 0.6646 | acc = 0.5944 | grad_norm = 8.2109
2025-12-09 05:46:59,413 | [Step 6000] loss = 0.6639 | acc = 0.6062 | grad_norm = 4.3658
2025-12-09 05:50:41,772 | [Step 6200] loss = 0.6586 | acc = 0.6006 | grad_norm = 3.4790
2025-12-09 05:54:24,066 | [Step 6400] loss = 0.6605 | acc = 0.6194 | grad_norm = 9.2464
2025-12-09 05:58:06,382 | [Step 6600] loss = 0.6621 | acc = 0.6188 | grad_norm = 6.8513
2025-12-09 06:01:48,684 | [Step 6800] loss = 0.6510 | acc = 0.6062 | grad_norm = 3.9121
2025-12-09 06:05:31,013 | [Step 7000] loss = 0.6421 | acc = 0.6219 | grad_norm = 12.1473
2025-12-09 06:09:13,308 | [Step 7200] loss = 0.6477 | acc = 0.6200 | grad_norm = 12.4347
2025-12-09 06:12:55,614 | [Step 7400] loss = 0.6514 | acc = 0.6044 | grad_norm = 5.5943
2025-12-09 06:16:37,862 | [Step 7600] loss = 0.6389 | acc = 0.6169 | grad_norm = 24.2207
2025-12-09 06:20:20,170 | [Step 7800] loss = 0.6397 | acc = 0.6081 | grad_norm = 17.1775
2025-12-09 06:24:02,468 | [Step 8000] loss = 0.6327 | acc = 0.6238 | grad_norm = 12.4461
2025-12-09 06:27:44,733 | [Step 8200] loss = 0.6452 | acc = 0.6125 | grad_norm = 6.1647
2025-12-09 06:31:26,990 | [Step 8400] loss = 0.6350 | acc = 0.6362 | grad_norm = 5.6298
2025-12-09 06:35:09,301 | [Step 8600] loss = 0.6603 | acc = 0.6162 | grad_norm = 8.6875
2025-12-09 06:38:51,528 | [Step 8800] loss = 0.6271 | acc = 0.6294 | grad_norm = 4.2266
2025-12-09 06:42:33,876 | [Step 9000] loss = 0.6402 | acc = 0.6238 | grad_norm = 3.9742
2025-12-09 06:46:16,208 | [Step 9200] loss = 0.6577 | acc = 0.6044 | grad_norm = 6.3671
2025-12-09 06:49:58,558 | [Step 9400] loss = 0.6397 | acc = 0.6300 | grad_norm = 3.7779
2025-12-09 06:53:40,808 | [Step 9600] loss = 0.6383 | acc = 0.6294 | grad_norm = 7.7451
2025-12-09 06:57:23,066 | [Step 9800] loss = 0.6351 | acc = 0.6231 | grad_norm = 7.8765
2025-12-09 07:01:05,361 | [Step 10000] loss = 0.6304 | acc = 0.6431 | grad_norm = 4.7458
2025-12-09 07:04:47,855 | [Step 10200] loss = 0.6515 | acc = 0.6225 | grad_norm = 13.1955
2025-12-09 07:08:31,640 | [Step 10400] loss = 0.6370 | acc = 0.6300 | grad_norm = 6.3747
2025-12-09 07:12:14,283 | [Step 10600] loss = 0.6282 | acc = 0.6531 | grad_norm = 4.1006
2025-12-09 07:15:56,995 | [Step 10800] loss = 0.6402 | acc = 0.6212 | grad_norm = 3.7671
2025-12-09 07:19:39,765 | [Step 11000] loss = 0.6419 | acc = 0.6194 | grad_norm = 9.3097
2025-12-09 07:23:22,475 | [Step 11200] loss = 0.6347 | acc = 0.6194 | grad_norm = 9.2594
2025-12-09 07:27:05,263 | [Step 11400] loss = 0.6308 | acc = 0.6450 | grad_norm = 10.4416
2025-12-09 07:30:48,051 | [Step 11600] loss = 0.6262 | acc = 0.6381 | grad_norm = 10.0122
2025-12-09 07:34:30,889 | [Step 11800] loss = 0.6411 | acc = 0.6156 | grad_norm = 5.7487
2025-12-09 07:38:13,628 | [Step 12000] loss = 0.6403 | acc = 0.6200 | grad_norm = 4.1329
2025-12-09 07:41:56,382 | [Step 12200] loss = 0.6348 | acc = 0.6200 | grad_norm = 4.3038
2025-12-09 07:45:39,160 | [Step 12400] loss = 0.6266 | acc = 0.6144 | grad_norm = 3.5825
2025-12-09 07:49:21,828 | [Step 12600] loss = 0.6360 | acc = 0.6212 | grad_norm = 11.4197
2025-12-09 07:53:04,609 | [Step 12800] loss = 0.6288 | acc = 0.6369 | grad_norm = 3.4224
2025-12-09 07:56:47,377 | [Step 13000] loss = 0.6117 | acc = 0.6494 | grad_norm = 7.7748
2025-12-09 08:00:30,161 | [Step 13200] loss = 0.6226 | acc = 0.6394 | grad_norm = 13.9226
2025-12-09 08:04:12,992 | [Step 13400] loss = 0.6170 | acc = 0.6675 | grad_norm = 13.3237
2025-12-09 08:07:55,747 | [Step 13600] loss = 0.6196 | acc = 0.6356 | grad_norm = 6.8540
2025-12-09 08:11:38,598 | [Step 13800] loss = 0.6456 | acc = 0.6275 | grad_norm = 2.8742
2025-12-09 08:15:21,316 | [Step 14000] loss = 0.6287 | acc = 0.6300 | grad_norm = 16.9043
2025-12-09 08:19:04,193 | [Step 14200] loss = 0.6429 | acc = 0.6294 | grad_norm = 7.8623
2025-12-09 08:22:47,102 | [Step 14400] loss = 0.6179 | acc = 0.6625 | grad_norm = 2.9274
2025-12-09 08:26:29,903 | [Step 14600] loss = 0.6292 | acc = 0.6344 | grad_norm = 5.9970
2025-12-09 08:30:12,729 | [Step 14800] loss = 0.6232 | acc = 0.6469 | grad_norm = 4.5726
2025-12-09 08:33:55,586 | [Step 15000] loss = 0.6135 | acc = 0.6475 | grad_norm = 20.3504
2025-12-09 08:37:38,462 | [Step 15200] loss = 0.6179 | acc = 0.6456 | grad_norm = 3.7962
2025-12-09 08:41:21,281 | [Step 15400] loss = 0.6183 | acc = 0.6444 | grad_norm = 3.6032
2025-12-09 08:45:04,159 | [Step 15600] loss = 0.6292 | acc = 0.6388 | grad_norm = 6.5873
2025-12-09 08:48:47,057 | [Step 15800] loss = 0.6134 | acc = 0.6406 | grad_norm = 6.7444
2025-12-09 08:52:29,993 | [Step 16000] loss = 0.6194 | acc = 0.6637 | grad_norm = 4.5426
2025-12-09 08:56:12,808 | [Step 16200] loss = 0.6154 | acc = 0.6625 | grad_norm = 3.0615
2025-12-09 08:59:55,576 | [Step 16400] loss = 0.6165 | acc = 0.6544 | grad_norm = 3.9407
2025-12-09 09:03:38,354 | [Step 16600] loss = 0.6222 | acc = 0.6444 | grad_norm = 2.6143
2025-12-09 09:07:21,174 | [Step 16800] loss = 0.5953 | acc = 0.6581 | grad_norm = 7.2591
2025-12-09 09:11:04,014 | [Step 17000] loss = 0.6200 | acc = 0.6431 | grad_norm = 5.1422
2025-12-09 09:14:46,904 | [Step 17200] loss = 0.6228 | acc = 0.6375 | grad_norm = 5.2479
2025-12-09 09:18:29,679 | [Step 17400] loss = 0.6220 | acc = 0.6587 | grad_norm = 4.9250
2025-12-09 09:22:12,749 | [Step 17600] loss = 0.6230 | acc = 0.6462 | grad_norm = 6.0644
2025-12-09 09:25:55,706 | [Step 17800] loss = 0.6323 | acc = 0.6275 | grad_norm = 8.0954
2025-12-09 09:29:38,573 | [Step 18000] loss = 0.6196 | acc = 0.6506 | grad_norm = 6.2142
2025-12-09 09:53:08,797 | [Epoch 1] Validation loss: 0.6112, Validation acc: 0.6316
2025-12-09 09:53:08,797 | ===== Epoch 2/5 =====
2025-12-09 09:55:12,030 | [Step 18200] loss = 0.3291 | acc = 0.3656 | grad_norm = 6.8580
2025-12-09 09:58:55,075 | [Step 18400] loss = 0.5880 | acc = 0.6837 | grad_norm = 7.7109
2025-12-09 10:02:38,009 | [Step 18600] loss = 0.6039 | acc = 0.6625 | grad_norm = 10.4555
2025-12-09 10:06:20,788 | [Step 18800] loss = 0.6046 | acc = 0.6737 | grad_norm = 3.7034
2025-12-09 10:10:03,796 | [Step 19000] loss = 0.5920 | acc = 0.6669 | grad_norm = 4.7767
2025-12-09 10:13:46,794 | [Step 19200] loss = 0.5795 | acc = 0.6925 | grad_norm = 3.7441
2025-12-09 10:17:29,675 | [Step 19400] loss = 0.5686 | acc = 0.6869 | grad_norm = 2.9862
2025-12-09 10:21:12,226 | [Step 19600] loss = 0.5915 | acc = 0.6831 | grad_norm = 8.9306
2025-12-09 10:24:54,714 | [Step 19800] loss = 0.6001 | acc = 0.6763 | grad_norm = 5.2700
2025-12-09 10:28:37,614 | [Step 20000] loss = 0.5724 | acc = 0.6925 | grad_norm = 6.1485
2025-12-09 10:32:20,674 | [Step 20200] loss = 0.5930 | acc = 0.6706 | grad_norm = 6.0542
2025-12-09 10:36:03,657 | [Step 20400] loss = 0.6014 | acc = 0.6725 | grad_norm = 11.1302
2025-12-09 10:39:46,646 | [Step 20600] loss = 0.5924 | acc = 0.6813 | grad_norm = 5.3662
2025-12-09 10:43:29,734 | [Step 20800] loss = 0.5920 | acc = 0.6763 | grad_norm = 7.0958
2025-12-09 10:47:12,560 | [Step 21000] loss = 0.6136 | acc = 0.6663 | grad_norm = 3.8052
2025-12-09 10:50:55,382 | [Step 21200] loss = 0.5882 | acc = 0.6994 | grad_norm = 6.9968
2025-12-09 10:54:38,630 | [Step 21400] loss = 0.5990 | acc = 0.6625 | grad_norm = 7.4897
2025-12-09 10:58:22,346 | [Step 21600] loss = 0.5760 | acc = 0.6900 | grad_norm = 6.9573
2025-12-09 11:02:06,449 | [Step 21800] loss = 0.5853 | acc = 0.6787 | grad_norm = 4.8777
2025-12-09 11:05:50,292 | [Step 22000] loss = 0.5914 | acc = 0.6875 | grad_norm = 7.8633
2025-12-09 11:09:34,073 | [Step 22200] loss = 0.5979 | acc = 0.6719 | grad_norm = 8.8385
2025-12-09 11:13:17,913 | [Step 22400] loss = 0.5741 | acc = 0.6781 | grad_norm = 3.7984
2025-12-09 11:17:01,830 | [Step 22600] loss = 0.5842 | acc = 0.6937 | grad_norm = 10.3109
2025-12-09 11:20:45,451 | [Step 22800] loss = 0.5835 | acc = 0.6831 | grad_norm = 5.5676
2025-12-09 11:24:29,078 | [Step 23000] loss = 0.5791 | acc = 0.6775 | grad_norm = 4.5817
2025-12-09 11:28:12,830 | [Step 23200] loss = 0.6019 | acc = 0.6694 | grad_norm = 4.4884
2025-12-09 11:31:56,712 | [Step 23400] loss = 0.5952 | acc = 0.6531 | grad_norm = 5.2340
2025-12-09 11:35:40,611 | [Step 23600] loss = 0.5929 | acc = 0.6769 | grad_norm = 8.1116
2025-12-09 11:39:24,468 | [Step 23800] loss = 0.5794 | acc = 0.6794 | grad_norm = 11.7145
2025-12-09 11:43:08,391 | [Step 24000] loss = 0.5962 | acc = 0.6787 | grad_norm = 5.3824
2025-12-09 11:46:52,165 | [Step 24200] loss = 0.5817 | acc = 0.6763 | grad_norm = 5.3193
2025-12-09 11:50:35,971 | [Step 24400] loss = 0.5863 | acc = 0.6687 | grad_norm = 4.6134
2025-12-09 11:54:19,965 | [Step 24600] loss = 0.5964 | acc = 0.6750 | grad_norm = 5.3777
2025-12-09 11:58:03,698 | [Step 24800] loss = 0.5845 | acc = 0.6819 | grad_norm = 5.4776
2025-12-09 12:01:47,397 | [Step 25000] loss = 0.6107 | acc = 0.6525 | grad_norm = 4.1704
2025-12-09 12:05:31,045 | [Step 25200] loss = 0.5733 | acc = 0.6981 | grad_norm = 8.3335
2025-12-09 12:09:14,936 | [Step 25400] loss = 0.5808 | acc = 0.6825 | grad_norm = 3.9599
2025-12-09 12:12:58,650 | [Step 25600] loss = 0.5855 | acc = 0.6925 | grad_norm = 3.1735
2025-12-09 12:16:42,307 | [Step 25800] loss = 0.5909 | acc = 0.6706 | grad_norm = 5.8163
2025-12-09 12:20:25,964 | [Step 26000] loss = 0.5942 | acc = 0.6694 | grad_norm = 4.3232
2025-12-09 12:24:09,644 | [Step 26200] loss = 0.5839 | acc = 0.6925 | grad_norm = 7.1313
2025-12-09 12:27:53,345 | [Step 26400] loss = 0.5915 | acc = 0.6781 | grad_norm = 8.3925
2025-12-09 12:31:36,928 | [Step 26600] loss = 0.5992 | acc = 0.6625 | grad_norm = 23.1364
2025-12-09 12:35:20,576 | [Step 26800] loss = 0.5791 | acc = 0.6775 | grad_norm = 6.1204
2025-12-09 12:39:04,365 | [Step 27000] loss = 0.5981 | acc = 0.6750 | grad_norm = 4.6424
2025-12-09 12:42:48,029 | [Step 27200] loss = 0.5962 | acc = 0.6650 | grad_norm = 4.0108
2025-12-09 12:46:31,723 | [Step 27400] loss = 0.5942 | acc = 0.6737 | grad_norm = 5.2849
2025-12-09 12:50:15,574 | [Step 27600] loss = 0.5890 | acc = 0.6744 | grad_norm = 7.7858
2025-12-09 12:53:59,329 | [Step 27800] loss = 0.5860 | acc = 0.6613 | grad_norm = 6.5750
2025-12-09 12:57:42,933 | [Step 28000] loss = 0.5813 | acc = 0.6900 | grad_norm = 6.2171
2025-12-09 13:01:26,654 | [Step 28200] loss = 0.5962 | acc = 0.6706 | grad_norm = 4.2983
2025-12-09 13:05:10,308 | [Step 28400] loss = 0.5751 | acc = 0.6775 | grad_norm = 7.0010
2025-12-09 13:08:54,109 | [Step 28600] loss = 0.5983 | acc = 0.6744 | grad_norm = 6.9528
2025-12-09 13:12:37,937 | [Step 28800] loss = 0.5872 | acc = 0.6713 | grad_norm = 6.9389
2025-12-09 13:16:21,762 | [Step 29000] loss = 0.5829 | acc = 0.6869 | grad_norm = 4.4790
2025-12-09 13:20:05,662 | [Step 29200] loss = 0.5956 | acc = 0.6775 | grad_norm = 7.9045
2025-12-09 13:23:49,451 | [Step 29400] loss = 0.5708 | acc = 0.6925 | grad_norm = 6.0489
2025-12-09 13:27:33,430 | [Step 29600] loss = 0.5774 | acc = 0.6913 | grad_norm = 7.8690
2025-12-09 13:31:17,412 | [Step 29800] loss = 0.6032 | acc = 0.6656 | grad_norm = 5.2848
2025-12-09 13:35:01,544 | [Step 30000] loss = 0.5952 | acc = 0.6625 | grad_norm = 5.7968
2025-12-09 13:38:45,595 | [Step 30200] loss = 0.5751 | acc = 0.6875 | grad_norm = 4.6497
2025-12-09 13:42:29,676 | [Step 30400] loss = 0.5864 | acc = 0.6919 | grad_norm = 4.9818
2025-12-09 13:46:13,652 | [Step 30600] loss = 0.5880 | acc = 0.6656 | grad_norm = 12.2787
2025-12-09 13:49:57,659 | [Step 30800] loss = 0.6102 | acc = 0.6600 | grad_norm = 12.4402
2025-12-09 13:53:41,598 | [Step 31000] loss = 0.5842 | acc = 0.6763 | grad_norm = 5.3676
2025-12-09 13:57:25,524 | [Step 31200] loss = 0.5893 | acc = 0.6825 | grad_norm = 6.6303
2025-12-09 14:01:09,415 | [Step 31400] loss = 0.5992 | acc = 0.6550 | grad_norm = 8.2773
2025-12-09 14:04:53,476 | [Step 31600] loss = 0.5814 | acc = 0.6900 | grad_norm = 8.6043
2025-12-09 14:08:37,645 | [Step 31800] loss = 0.6008 | acc = 0.6600 | grad_norm = 6.0958
2025-12-09 14:12:33,357 | [Step 32000] loss = 0.6024 | acc = 0.6687 | grad_norm = 6.3462
2025-12-09 14:16:35,188 | [Step 32200] loss = 0.5845 | acc = 0.6644 | grad_norm = 3.9885
2025-12-09 14:20:18,912 | [Step 32400] loss = 0.5780 | acc = 0.6837 | grad_norm = 4.6217
2025-12-09 14:24:02,799 | [Step 32600] loss = 0.5646 | acc = 0.6881 | grad_norm = 5.2192
2025-12-09 14:27:46,646 | [Step 32800] loss = 0.6042 | acc = 0.6744 | grad_norm = 14.8843
2025-12-09 14:31:30,489 | [Step 33000] loss = 0.5639 | acc = 0.6881 | grad_norm = 3.8713
2025-12-09 14:35:14,471 | [Step 33200] loss = 0.5960 | acc = 0.6650 | grad_norm = 3.9808
2025-12-09 14:38:58,335 | [Step 33400] loss = 0.6054 | acc = 0.6719 | grad_norm = 6.6028
2025-12-09 14:42:42,075 | [Step 33600] loss = 0.5856 | acc = 0.6744 | grad_norm = 6.8586
2025-12-09 14:46:25,948 | [Step 33800] loss = 0.5898 | acc = 0.6869 | grad_norm = 5.5969
2025-12-09 14:50:09,728 | [Step 34000] loss = 0.5762 | acc = 0.6850 | grad_norm = 12.1948
2025-12-09 14:53:53,730 | [Step 34200] loss = 0.5820 | acc = 0.6831 | grad_norm = 3.9212
2025-12-09 14:57:37,652 | [Step 34400] loss = 0.5872 | acc = 0.6706 | grad_norm = 9.0295
2025-12-09 15:01:21,411 | [Step 34600] loss = 0.5677 | acc = 0.6937 | grad_norm = 3.2031
2025-12-09 15:05:05,266 | [Step 34800] loss = 0.5906 | acc = 0.6869 | grad_norm = 8.0342
2025-12-09 15:08:49,241 | [Step 35000] loss = 0.5948 | acc = 0.6619 | grad_norm = 7.3962
2025-12-09 15:12:33,112 | [Step 35200] loss = 0.5869 | acc = 0.6844 | grad_norm = 4.6693
2025-12-09 15:16:17,020 | [Step 35400] loss = 0.5970 | acc = 0.6825 | grad_norm = 4.7083
2025-12-09 15:20:01,023 | [Step 35600] loss = 0.5821 | acc = 0.6669 | grad_norm = 4.5104
2025-12-09 15:23:45,044 | [Step 35800] loss = 0.5740 | acc = 0.6756 | grad_norm = 4.9823
2025-12-09 15:27:29,112 | [Step 36000] loss = 0.5996 | acc = 0.6737 | grad_norm = 7.3533
2025-12-09 15:52:45,498 | [Epoch 2] Validation loss: 0.6109, Validation acc: 0.6428
2025-12-09 15:52:45,499 | ===== Epoch 3/5 =====
2025-12-09 15:53:07,896 | [Step 36200] loss = 0.0520 | acc = 0.0731 | grad_norm = 16.0052
2025-12-09 15:56:51,891 | [Step 36400] loss = 0.5248 | acc = 0.7200 | grad_norm = 8.2206
2025-12-09 16:00:35,773 | [Step 36600] loss = 0.5463 | acc = 0.7231 | grad_norm = 11.8359
2025-12-09 16:04:19,829 | [Step 36800] loss = 0.5367 | acc = 0.7238 | grad_norm = 9.6422
2025-12-09 16:08:03,665 | [Step 37000] loss = 0.5397 | acc = 0.7219 | grad_norm = 5.5103
2025-12-09 16:11:47,362 | [Step 37200] loss = 0.4981 | acc = 0.7381 | grad_norm = 9.9934
2025-12-09 16:15:31,183 | [Step 37400] loss = 0.5508 | acc = 0.7244 | grad_norm = 9.9848
2025-12-09 16:19:15,037 | [Step 37600] loss = 0.5138 | acc = 0.7350 | grad_norm = 33.8850
2025-12-09 16:22:58,977 | [Step 37800] loss = 0.5041 | acc = 0.7444 | grad_norm = 9.4760
2025-12-09 16:26:42,592 | [Step 38000] loss = 0.5188 | acc = 0.7338 | grad_norm = 9.9939
2025-12-09 16:30:26,249 | [Step 38200] loss = 0.5103 | acc = 0.7462 | grad_norm = 8.4019
2025-12-09 16:34:09,816 | [Step 38400] loss = 0.5135 | acc = 0.7356 | grad_norm = 10.0548
2025-12-09 16:37:53,756 | [Step 38600] loss = 0.5318 | acc = 0.7225 | grad_norm = 7.1674
2025-12-09 16:41:37,273 | [Step 38800] loss = 0.5145 | acc = 0.7331 | grad_norm = 6.3261
2025-12-09 16:45:20,981 | [Step 39000] loss = 0.5208 | acc = 0.7338 | grad_norm = 11.7762
2025-12-09 16:49:04,704 | [Step 39200] loss = 0.5205 | acc = 0.7312 | grad_norm = 5.8662
2025-12-09 16:52:48,372 | [Step 39400] loss = 0.4978 | acc = 0.7550 | grad_norm = 6.7457
2025-12-09 16:56:31,890 | [Step 39600] loss = 0.5460 | acc = 0.7219 | grad_norm = 16.6831
2025-12-09 17:00:15,445 | [Step 39800] loss = 0.5134 | acc = 0.7462 | grad_norm = 10.3974
2025-12-09 17:03:59,179 | [Step 40000] loss = 0.5186 | acc = 0.7338 | grad_norm = 9.6813
2025-12-09 17:07:42,778 | [Step 40200] loss = 0.5232 | acc = 0.7444 | grad_norm = 8.4417
2025-12-09 17:11:26,713 | [Step 40400] loss = 0.5306 | acc = 0.7269 | grad_norm = 11.3828
2025-12-09 17:15:10,427 | [Step 40600] loss = 0.5276 | acc = 0.7244 | grad_norm = 12.5229
2025-12-09 17:19:14,662 | [Step 40800] loss = 0.5400 | acc = 0.7244 | grad_norm = 9.8857
2025-12-09 17:23:05,908 | [Step 41000] loss = 0.5121 | acc = 0.7331 | grad_norm = 10.7116
2025-12-09 17:27:03,110 | [Step 41200] loss = 0.5399 | acc = 0.7225 | grad_norm = 11.6059
2025-12-09 17:31:01,643 | [Step 41400] loss = 0.5326 | acc = 0.7219 | grad_norm = 11.2613
2025-12-09 17:34:47,565 | [Step 41600] loss = 0.5158 | acc = 0.7256 | grad_norm = 7.0231
2025-12-09 17:38:31,139 | [Step 41800] loss = 0.4968 | acc = 0.7500 | grad_norm = 12.3063
2025-12-09 17:42:15,159 | [Step 42000] loss = 0.5242 | acc = 0.7225 | grad_norm = 8.3419
2025-12-09 17:46:27,588 | [Step 42200] loss = 0.5012 | acc = 0.7569 | grad_norm = 6.6138
2025-12-09 17:50:34,064 | [Step 42400] loss = 0.5222 | acc = 0.7175 | grad_norm = 9.7294
2025-12-09 17:54:24,443 | [Step 42600] loss = 0.5133 | acc = 0.7462 | grad_norm = 7.0511
2025-12-09 17:58:38,609 | [Step 42800] loss = 0.5551 | acc = 0.7037 | grad_norm = 20.5417
2025-12-09 18:02:22,598 | [Step 43000] loss = 0.5100 | acc = 0.7350 | grad_norm = 9.9972
2025-12-09 18:06:06,505 | [Step 43200] loss = 0.5362 | acc = 0.7300 | grad_norm = 15.0721
2025-12-09 18:09:50,221 | [Step 43400] loss = 0.5383 | acc = 0.7244 | grad_norm = 5.4145
2025-12-09 18:13:33,949 | [Step 43600] loss = 0.5334 | acc = 0.7150 | grad_norm = 4.5250
2025-12-09 18:17:17,688 | [Step 43800] loss = 0.5167 | acc = 0.7388 | grad_norm = 9.6906
2025-12-09 18:21:01,377 | [Step 44000] loss = 0.5084 | acc = 0.7356 | grad_norm = 24.5999
2025-12-09 18:24:45,083 | [Step 44200] loss = 0.5472 | acc = 0.7250 | grad_norm = 8.8328
2025-12-09 18:28:28,836 | [Step 44400] loss = 0.5070 | acc = 0.7494 | grad_norm = 9.4394
2025-12-09 18:32:12,652 | [Step 44600] loss = 0.5420 | acc = 0.7188 | grad_norm = 10.5972
2025-12-09 18:35:56,396 | [Step 44800] loss = 0.5000 | acc = 0.7525 | grad_norm = 15.7169
2025-12-09 18:39:40,165 | [Step 45000] loss = 0.5228 | acc = 0.7306 | grad_norm = 9.3666
2025-12-09 18:43:23,871 | [Step 45200] loss = 0.5137 | acc = 0.7444 | grad_norm = 13.4920
2025-12-09 18:47:07,570 | [Step 45400] loss = 0.4821 | acc = 0.7506 | grad_norm = 8.1147
2025-12-09 18:50:51,266 | [Step 45600] loss = 0.5371 | acc = 0.7294 | grad_norm = 6.3426
2025-12-09 18:54:34,989 | [Step 45800] loss = 0.5381 | acc = 0.7225 | grad_norm = 8.1063
2025-12-09 18:58:18,783 | [Step 46000] loss = 0.5373 | acc = 0.7356 | grad_norm = 10.1370
2025-12-09 19:02:02,522 | [Step 46200] loss = 0.5211 | acc = 0.7412 | grad_norm = 11.9608
2025-12-09 19:05:46,395 | [Step 46400] loss = 0.5321 | acc = 0.7225 | grad_norm = 15.2575
2025-12-09 19:09:30,070 | [Step 46600] loss = 0.5181 | acc = 0.7406 | grad_norm = 6.0183
2025-12-09 19:13:13,873 | [Step 46800] loss = 0.5158 | acc = 0.7362 | grad_norm = 5.8582
2025-12-09 19:16:57,453 | [Step 47000] loss = 0.5421 | acc = 0.7244 | grad_norm = 7.9904
2025-12-09 19:20:41,194 | [Step 47200] loss = 0.5289 | acc = 0.7362 | grad_norm = 10.8460
2025-12-09 19:24:25,125 | [Step 47400] loss = 0.5273 | acc = 0.7125 | grad_norm = 12.6115
2025-12-09 19:28:08,902 | [Step 47600] loss = 0.5272 | acc = 0.7338 | grad_norm = 12.0091
2025-12-09 19:31:52,690 | [Step 47800] loss = 0.5439 | acc = 0.7219 | grad_norm = 6.3697
2025-12-09 19:35:36,505 | [Step 48000] loss = 0.5017 | acc = 0.7344 | grad_norm = 10.4733
2025-12-09 19:39:20,275 | [Step 48200] loss = 0.5302 | acc = 0.7288 | grad_norm = 14.3042
2025-12-09 19:43:03,990 | [Step 48400] loss = 0.4994 | acc = 0.7469 | grad_norm = 9.3619
2025-12-09 19:46:47,716 | [Step 48600] loss = 0.5224 | acc = 0.7306 | grad_norm = 8.5374
2025-12-09 19:50:31,474 | [Step 48800] loss = 0.5022 | acc = 0.7394 | grad_norm = 3.8279
2025-12-09 19:54:15,248 | [Step 49000] loss = 0.5262 | acc = 0.7325 | grad_norm = 8.2588
2025-12-09 19:57:58,784 | [Step 49200] loss = 0.5158 | acc = 0.7388 | grad_norm = 7.1663
2025-12-09 20:01:42,371 | [Step 49400] loss = 0.5346 | acc = 0.7269 | grad_norm = 7.1535
2025-12-09 20:05:26,064 | [Step 49600] loss = 0.5149 | acc = 0.7344 | grad_norm = 7.8114
2025-12-09 20:09:09,732 | [Step 49800] loss = 0.5266 | acc = 0.7312 | grad_norm = 7.6074
2025-12-09 20:12:53,324 | [Step 50000] loss = 0.5167 | acc = 0.7219 | grad_norm = 10.8753
2025-12-09 20:16:36,962 | [Step 50200] loss = 0.4976 | acc = 0.7431 | grad_norm = 5.7597
2025-12-09 20:20:20,680 | [Step 50400] loss = 0.5162 | acc = 0.7506 | grad_norm = 25.1952
2025-12-09 20:24:04,300 | [Step 50600] loss = 0.5145 | acc = 0.7419 | grad_norm = 7.4631
2025-12-09 20:27:48,033 | [Step 50800] loss = 0.5351 | acc = 0.7381 | grad_norm = 4.7446
2025-12-09 20:31:31,647 | [Step 51000] loss = 0.4907 | acc = 0.7638 | grad_norm = 8.3653
2025-12-09 20:35:15,258 | [Step 51200] loss = 0.5078 | acc = 0.7544 | grad_norm = 7.5223
2025-12-09 20:38:58,830 | [Step 51400] loss = 0.5106 | acc = 0.7412 | grad_norm = 10.9880
2025-12-09 20:42:42,390 | [Step 51600] loss = 0.5298 | acc = 0.7244 | grad_norm = 7.5026
2025-12-09 20:46:25,972 | [Step 51800] loss = 0.5110 | acc = 0.7369 | grad_norm = 6.9336
2025-12-09 20:50:09,571 | [Step 52000] loss = 0.5374 | acc = 0.7225 | grad_norm = 9.7960
2025-12-09 20:53:53,190 | [Step 52200] loss = 0.5239 | acc = 0.7469 | grad_norm = 13.1277
2025-12-09 20:57:36,746 | [Step 52400] loss = 0.5166 | acc = 0.7419 | grad_norm = 7.7835
2025-12-09 21:01:20,374 | [Step 52600] loss = 0.4981 | acc = 0.7500 | grad_norm = 9.5308
2025-12-09 21:05:04,178 | [Step 52800] loss = 0.5131 | acc = 0.7425 | grad_norm = 8.4038
2025-12-09 21:08:48,040 | [Step 53000] loss = 0.5194 | acc = 0.7500 | grad_norm = 7.8064
2025-12-09 21:12:31,682 | [Step 53200] loss = 0.5064 | acc = 0.7500 | grad_norm = 13.5888
2025-12-09 21:16:15,411 | [Step 53400] loss = 0.5185 | acc = 0.7506 | grad_norm = 21.6658
2025-12-09 21:19:59,190 | [Step 53600] loss = 0.5068 | acc = 0.7469 | grad_norm = 15.6287
2025-12-09 21:23:42,654 | [Step 53800] loss = 0.5206 | acc = 0.7381 | grad_norm = 11.8871
2025-12-09 21:27:26,210 | [Step 54000] loss = 0.5163 | acc = 0.7456 | grad_norm = 16.1169
2025-12-09 21:31:09,673 | [Step 54200] loss = 0.5610 | acc = 0.7188 | grad_norm = 7.1199
2025-12-09 21:54:22,661 | [Epoch 3] Validation loss: 0.6546, Validation acc: 0.6413
2025-12-09 21:54:22,662 | ===== Epoch 4/5 =====
2025-12-09 21:56:48,210 | [Step 54400] loss = 0.2908 | acc = 0.5088 | grad_norm = 6.7544
2025-12-09 22:00:31,861 | [Step 54600] loss = 0.4535 | acc = 0.7875 | grad_norm = 16.4151
2025-12-09 22:04:15,521 | [Step 54800] loss = 0.4449 | acc = 0.7906 | grad_norm = 10.3233
2025-12-09 22:07:59,177 | [Step 55000] loss = 0.4273 | acc = 0.7937 | grad_norm = 7.4583
2025-12-09 22:11:42,812 | [Step 55200] loss = 0.4353 | acc = 0.8006 | grad_norm = 7.6208
2025-12-09 22:15:26,431 | [Step 55400] loss = 0.4437 | acc = 0.7875 | grad_norm = 11.9775
2025-12-09 22:19:10,001 | [Step 55600] loss = 0.4416 | acc = 0.7844 | grad_norm = 8.8518
2025-12-09 22:22:53,676 | [Step 55800] loss = 0.4404 | acc = 0.8000 | grad_norm = 9.3677
2025-12-09 22:26:37,843 | [Step 56000] loss = 0.4168 | acc = 0.8094 | grad_norm = 6.8910
2025-12-09 22:30:21,526 | [Step 56200] loss = 0.4116 | acc = 0.8075 | grad_norm = 7.4905
2025-12-09 22:34:05,209 | [Step 56400] loss = 0.4711 | acc = 0.7750 | grad_norm = 18.2792
2025-12-09 22:37:48,932 | [Step 56600] loss = 0.4465 | acc = 0.7869 | grad_norm = 8.6185
2025-12-09 22:41:32,688 | [Step 56800] loss = 0.4407 | acc = 0.7987 | grad_norm = 6.9198
2025-12-09 22:45:16,434 | [Step 57000] loss = 0.4351 | acc = 0.7906 | grad_norm = 15.4334
2025-12-09 22:49:00,315 | [Step 57200] loss = 0.4351 | acc = 0.7969 | grad_norm = 10.3204
2025-12-09 22:52:44,215 | [Step 57400] loss = 0.4416 | acc = 0.7906 | grad_norm = 4.1783
2025-12-09 22:56:27,946 | [Step 57600] loss = 0.4444 | acc = 0.7856 | grad_norm = 20.8471
2025-12-09 23:00:11,723 | [Step 57800] loss = 0.4386 | acc = 0.7975 | grad_norm = 46.4910
2025-12-09 23:03:55,508 | [Step 58000] loss = 0.4393 | acc = 0.7906 | grad_norm = 18.5500
2025-12-09 23:07:39,329 | [Step 58200] loss = 0.4528 | acc = 0.7894 | grad_norm = 5.5139
2025-12-09 23:11:23,145 | [Step 58400] loss = 0.4373 | acc = 0.7956 | grad_norm = 11.7111
2025-12-09 23:15:06,909 | [Step 58600] loss = 0.4223 | acc = 0.8106 | grad_norm = 7.9107
2025-12-09 23:18:50,823 | [Step 58800] loss = 0.4463 | acc = 0.7994 | grad_norm = 7.2384
2025-12-09 23:22:34,675 | [Step 59000] loss = 0.4320 | acc = 0.7837 | grad_norm = 7.0391
2025-12-09 23:26:18,474 | [Step 59200] loss = 0.4372 | acc = 0.7994 | grad_norm = 7.1605
2025-12-09 23:30:02,300 | [Step 59400] loss = 0.4368 | acc = 0.8069 | grad_norm = 12.2431
2025-12-09 23:33:45,794 | [Step 59600] loss = 0.4268 | acc = 0.8156 | grad_norm = 5.2828
2025-12-09 23:37:29,395 | [Step 59800] loss = 0.4480 | acc = 0.7731 | grad_norm = 10.0612
2025-12-09 23:41:13,136 | [Step 60000] loss = 0.4486 | acc = 0.7837 | grad_norm = 7.1139
2025-12-09 23:44:56,922 | [Step 60200] loss = 0.4281 | acc = 0.7963 | grad_norm = 6.1921
2025-12-09 23:48:40,714 | [Step 60400] loss = 0.4335 | acc = 0.7881 | grad_norm = 10.5303
2025-12-09 23:52:24,582 | [Step 60600] loss = 0.4525 | acc = 0.7963 | grad_norm = 15.5691
2025-12-09 23:56:08,244 | [Step 60800] loss = 0.4448 | acc = 0.7981 | grad_norm = 30.6982
2025-12-09 23:59:51,992 | [Step 61000] loss = 0.4413 | acc = 0.8050 | grad_norm = 9.8101
2025-12-10 00:03:35,844 | [Step 61200] loss = 0.4297 | acc = 0.8063 | grad_norm = 12.2976
2025-12-10 00:07:19,733 | [Step 61400] loss = 0.4253 | acc = 0.8025 | grad_norm = 6.2257
2025-12-10 00:11:03,683 | [Step 61600] loss = 0.4477 | acc = 0.7837 | grad_norm = 16.3150
2025-12-10 00:14:47,513 | [Step 61800] loss = 0.4038 | acc = 0.8069 | grad_norm = 9.4891
2025-12-10 00:18:31,488 | [Step 62000] loss = 0.4481 | acc = 0.7900 | grad_norm = 6.6644
2025-12-10 00:22:15,099 | [Step 62200] loss = 0.4463 | acc = 0.7869 | grad_norm = 12.0299
2025-12-10 00:25:58,756 | [Step 62400] loss = 0.4308 | acc = 0.8031 | grad_norm = 14.5269
2025-12-10 00:29:42,500 | [Step 62600] loss = 0.4206 | acc = 0.8056 | grad_norm = 11.2951
2025-12-10 00:33:26,390 | [Step 62800] loss = 0.4365 | acc = 0.8050 | grad_norm = 16.8976
2025-12-10 00:37:10,181 | [Step 63000] loss = 0.4631 | acc = 0.7800 | grad_norm = 13.3650
2025-12-10 00:40:54,000 | [Step 63200] loss = 0.4360 | acc = 0.7881 | grad_norm = 11.2380
2025-12-10 00:44:37,767 | [Step 63400] loss = 0.4313 | acc = 0.7900 | grad_norm = 8.0331
2025-12-10 00:48:21,633 | [Step 63600] loss = 0.4581 | acc = 0.7825 | grad_norm = 18.6885
2025-12-10 00:52:05,362 | [Step 63800] loss = 0.4337 | acc = 0.7881 | grad_norm = 19.3361
2025-12-10 00:55:49,140 | [Step 64000] loss = 0.4227 | acc = 0.7956 | grad_norm = 11.5325
2025-12-10 00:59:32,915 | [Step 64200] loss = 0.4437 | acc = 0.7956 | grad_norm = 12.4386
2025-12-10 01:03:16,851 | [Step 64400] loss = 0.4530 | acc = 0.7881 | grad_norm = 8.2924
2025-12-10 01:07:00,719 | [Step 64600] loss = 0.4012 | acc = 0.8069 | grad_norm = 13.2199
2025-12-10 01:10:44,496 | [Step 64800] loss = 0.4233 | acc = 0.7981 | grad_norm = 5.9515
2025-12-10 01:14:28,228 | [Step 65000] loss = 0.4302 | acc = 0.8031 | grad_norm = 19.4422
2025-12-10 01:18:12,080 | [Step 65200] loss = 0.4480 | acc = 0.7837 | grad_norm = 14.8327
2025-12-10 01:21:55,984 | [Step 65400] loss = 0.4309 | acc = 0.7944 | grad_norm = 10.1347
2025-12-10 01:25:39,840 | [Step 65600] loss = 0.4452 | acc = 0.7956 | grad_norm = 12.1102
2025-12-10 01:29:23,729 | [Step 65800] loss = 0.4296 | acc = 0.8019 | grad_norm = 21.3506
2025-12-10 01:33:07,572 | [Step 66000] loss = 0.4439 | acc = 0.7850 | grad_norm = 7.9786
2025-12-10 01:36:51,294 | [Step 66200] loss = 0.4488 | acc = 0.7875 | grad_norm = 15.2165
2025-12-10 01:40:35,109 | [Step 66400] loss = 0.4762 | acc = 0.7875 | grad_norm = 13.0163
2025-12-10 01:44:19,083 | [Step 66600] loss = 0.4401 | acc = 0.7913 | grad_norm = 12.4283
2025-12-10 01:48:03,085 | [Step 66800] loss = 0.4300 | acc = 0.7856 | grad_norm = 8.4659
2025-12-10 01:51:47,078 | [Step 67000] loss = 0.4594 | acc = 0.7831 | grad_norm = 11.5447
2025-12-10 01:55:31,159 | [Step 67200] loss = 0.4337 | acc = 0.8050 | grad_norm = 12.0091
2025-12-10 01:59:15,196 | [Step 67400] loss = 0.4537 | acc = 0.8056 | grad_norm = 10.8855
2025-12-10 02:02:59,199 | [Step 67600] loss = 0.4169 | acc = 0.8056 | grad_norm = 29.0907
2025-12-10 02:06:43,302 | [Step 67800] loss = 0.4363 | acc = 0.7919 | grad_norm = 21.4813
2025-12-10 02:10:27,341 | [Step 68000] loss = 0.4111 | acc = 0.8069 | grad_norm = 14.1423
2025-12-10 02:14:11,380 | [Step 68200] loss = 0.4282 | acc = 0.8150 | grad_norm = 18.9173
2025-12-10 02:17:55,445 | [Step 68400] loss = 0.4623 | acc = 0.7788 | grad_norm = 17.6408
2025-12-10 02:21:39,356 | [Step 68600] loss = 0.4097 | acc = 0.7987 | grad_norm = 14.4308
2025-12-10 02:25:23,432 | [Step 68800] loss = 0.4268 | acc = 0.7981 | grad_norm = 16.1741
2025-12-10 02:29:07,474 | [Step 69000] loss = 0.4087 | acc = 0.8063 | grad_norm = 27.4970
2025-12-10 02:32:51,504 | [Step 69200] loss = 0.4399 | acc = 0.8050 | grad_norm = 10.4167
2025-12-10 02:36:35,570 | [Step 69400] loss = 0.4317 | acc = 0.8056 | grad_norm = 11.6917
2025-12-10 02:40:19,609 | [Step 69600] loss = 0.4452 | acc = 0.7919 | grad_norm = 13.3048
2025-12-10 02:44:03,621 | [Step 69800] loss = 0.4260 | acc = 0.8044 | grad_norm = 5.2280
2025-12-10 02:47:47,713 | [Step 70000] loss = 0.4280 | acc = 0.7981 | grad_norm = 9.5469
2025-12-10 02:51:31,727 | [Step 70200] loss = 0.4210 | acc = 0.7994 | grad_norm = 16.6498
2025-12-10 02:55:15,696 | [Step 70400] loss = 0.4539 | acc = 0.7850 | grad_norm = 11.5006
2025-12-10 02:58:59,706 | [Step 70600] loss = 0.4479 | acc = 0.7937 | grad_norm = 6.9652
2025-12-10 03:02:43,726 | [Step 70800] loss = 0.4274 | acc = 0.7906 | grad_norm = 12.6979
2025-12-10 03:06:27,741 | [Step 71000] loss = 0.4371 | acc = 0.7937 | grad_norm = 11.6123
2025-12-10 03:10:11,733 | [Step 71200] loss = 0.4378 | acc = 0.8013 | grad_norm = 11.2023
2025-12-10 03:13:55,827 | [Step 71400] loss = 0.4259 | acc = 0.7937 | grad_norm = 23.0369
2025-12-10 03:17:39,834 | [Step 71600] loss = 0.4470 | acc = 0.8025 | grad_norm = 13.2476
2025-12-10 03:21:23,810 | [Step 71800] loss = 0.4302 | acc = 0.7987 | grad_norm = 16.5008
2025-12-10 03:25:07,786 | [Step 72000] loss = 0.4706 | acc = 0.7756 | grad_norm = 17.6909
2025-12-10 03:28:51,744 | [Step 72200] loss = 0.4285 | acc = 0.7887 | grad_norm = 21.6286
2025-12-10 03:53:46,442 | [Epoch 4] Validation loss: 0.7718, Validation acc: 0.6367
2025-12-10 03:53:46,442 | ===== Epoch 5/5 =====
2025-12-10 03:54:31,322 | [Step 72400] loss = 0.0696 | acc = 0.1681 | grad_norm = 6.9785
2025-12-10 03:58:15,309 | [Step 72600] loss = 0.3496 | acc = 0.8406 | grad_norm = 11.9636
2025-12-10 04:01:59,219 | [Step 72800] loss = 0.3432 | acc = 0.8438 | grad_norm = 3.3461
2025-12-10 04:05:43,087 | [Step 73000] loss = 0.3910 | acc = 0.8275 | grad_norm = 13.7707
2025-12-10 04:09:27,165 | [Step 73200] loss = 0.3460 | acc = 0.8456 | grad_norm = 7.4077
2025-12-10 04:13:11,041 | [Step 73400] loss = 0.3912 | acc = 0.8313 | grad_norm = 11.6518
2025-12-10 04:16:55,014 | [Step 73600] loss = 0.3618 | acc = 0.8287 | grad_norm = 17.2154
2025-12-10 04:20:39,023 | [Step 73800] loss = 0.3686 | acc = 0.8375 | grad_norm = 16.3657
2025-12-10 04:24:22,896 | [Step 74000] loss = 0.3503 | acc = 0.8462 | grad_norm = 6.6125
2025-12-10 04:28:06,915 | [Step 74200] loss = 0.3696 | acc = 0.8381 | grad_norm = 6.0448
2025-12-10 04:31:50,854 | [Step 74400] loss = 0.3644 | acc = 0.8344 | grad_norm = 15.7029
2025-12-10 04:35:34,803 | [Step 74600] loss = 0.3589 | acc = 0.8344 | grad_norm = 16.9532
2025-12-10 04:39:18,860 | [Step 74800] loss = 0.4140 | acc = 0.8044 | grad_norm = 15.9076
2025-12-10 04:43:02,812 | [Step 75000] loss = 0.3377 | acc = 0.8475 | grad_norm = 18.2138
2025-12-10 04:46:46,894 | [Step 75200] loss = 0.3708 | acc = 0.8287 | grad_norm = 29.5381
2025-12-10 04:50:30,863 | [Step 75400] loss = 0.3784 | acc = 0.8244 | grad_norm = 23.0700
2025-12-10 04:54:14,785 | [Step 75600] loss = 0.3537 | acc = 0.8300 | grad_norm = 13.4185
2025-12-10 04:57:58,811 | [Step 75800] loss = 0.3410 | acc = 0.8469 | grad_norm = 17.8679
2025-12-10 05:01:42,710 | [Step 76000] loss = 0.3445 | acc = 0.8556 | grad_norm = 14.1637
2025-12-10 05:05:26,735 | [Step 76200] loss = 0.4048 | acc = 0.8344 | grad_norm = 55.7109
2025-12-10 05:09:10,587 | [Step 76400] loss = 0.3755 | acc = 0.8344 | grad_norm = 6.8022
2025-12-10 05:12:54,420 | [Step 76600] loss = 0.3708 | acc = 0.8337 | grad_norm = 14.5780
2025-12-10 05:16:38,297 | [Step 76800] loss = 0.3817 | acc = 0.8263 | grad_norm = 9.3223
2025-12-10 05:20:21,969 | [Step 77000] loss = 0.3760 | acc = 0.8256 | grad_norm = 33.3033
2025-12-10 05:24:05,701 | [Step 77200] loss = 0.4125 | acc = 0.8163 | grad_norm = 21.5250
2025-12-10 05:27:49,469 | [Step 77400] loss = 0.3860 | acc = 0.8287 | grad_norm = 12.2004
2025-12-10 05:31:33,206 | [Step 77600] loss = 0.3683 | acc = 0.8419 | grad_norm = 20.7007
2025-12-10 05:35:17,130 | [Step 77800] loss = 0.3761 | acc = 0.8313 | grad_norm = 15.8666
2025-12-10 05:39:00,882 | [Step 78000] loss = 0.3366 | acc = 0.8456 | grad_norm = 6.5553
2025-12-10 05:42:44,882 | [Step 78200] loss = 0.3885 | acc = 0.8206 | grad_norm = 10.1408
2025-12-10 05:46:28,764 | [Step 78400] loss = 0.3681 | acc = 0.8319 | grad_norm = 14.9247
2025-12-10 05:50:12,589 | [Step 78600] loss = 0.3599 | acc = 0.8469 | grad_norm = 15.6684
2025-12-10 05:53:56,334 | [Step 78800] loss = 0.3525 | acc = 0.8406 | grad_norm = 9.8077
2025-12-10 05:57:40,145 | [Step 79000] loss = 0.3747 | acc = 0.8281 | grad_norm = 12.6907
2025-12-10 06:01:24,079 | [Step 79200] loss = 0.3879 | acc = 0.8344 | grad_norm = 25.2779
2025-12-10 06:05:07,924 | [Step 79400] loss = 0.3583 | acc = 0.8506 | grad_norm = 20.8307
2025-12-10 06:08:51,710 | [Step 79600] loss = 0.3633 | acc = 0.8444 | grad_norm = 20.5648
2025-12-10 06:12:35,466 | [Step 79800] loss = 0.4148 | acc = 0.8231 | grad_norm = 18.1649
2025-12-10 06:16:19,181 | [Step 80000] loss = 0.3650 | acc = 0.8425 | grad_norm = 17.3666
2025-12-10 06:20:03,040 | [Step 80200] loss = 0.3930 | acc = 0.8263 | grad_norm = 11.7091
2025-12-10 06:23:46,860 | [Step 80400] loss = 0.3502 | acc = 0.8481 | grad_norm = 8.4599
2025-12-10 06:27:30,805 | [Step 80600] loss = 0.3836 | acc = 0.8219 | grad_norm = 11.6298
2025-12-10 06:31:14,696 | [Step 80800] loss = 0.3519 | acc = 0.8456 | grad_norm = 26.2598
2025-12-10 06:34:58,504 | [Step 81000] loss = 0.3408 | acc = 0.8444 | grad_norm = 13.6803
2025-12-10 06:38:42,410 | [Step 81200] loss = 0.3632 | acc = 0.8375 | grad_norm = 3.1327
2025-12-10 06:42:26,128 | [Step 81400] loss = 0.3660 | acc = 0.8375 | grad_norm = 17.8365
2025-12-10 06:46:09,893 | [Step 81600] loss = 0.3849 | acc = 0.8325 | grad_norm = 41.1836
2025-12-10 06:49:53,692 | [Step 81800] loss = 0.3592 | acc = 0.8475 | grad_norm = 15.1622
2025-12-10 06:53:37,329 | [Step 82000] loss = 0.3928 | acc = 0.8237 | grad_norm = 4.7313
2025-12-10 06:57:21,080 | [Step 82200] loss = inf | acc = 0.8237 | grad_norm = 9.6672
2025-12-10 07:01:04,837 | [Step 82400] loss = 0.3732 | acc = 0.8275 | grad_norm = 8.9848
2025-12-10 07:04:48,571 | [Step 82600] loss = 0.3840 | acc = 0.8387 | grad_norm = 12.8415
2025-12-10 07:08:32,403 | [Step 82800] loss = 0.3768 | acc = 0.8244 | grad_norm = 19.0474
2025-12-10 07:12:16,056 | [Step 83000] loss = 0.3555 | acc = 0.8400 | grad_norm = 9.0539
2025-12-10 07:15:59,779 | [Step 83200] loss = 0.3618 | acc = 0.8488 | grad_norm = 21.0856
2025-12-10 07:19:43,579 | [Step 83400] loss = 0.3571 | acc = 0.8475 | grad_norm = 25.9618
2025-12-10 07:23:27,395 | [Step 83600] loss = 0.3639 | acc = 0.8350 | grad_norm = 16.4196
2025-12-10 07:27:11,183 | [Step 83800] loss = 0.3633 | acc = 0.8356 | grad_norm = 21.7205
2025-12-10 07:30:54,900 | [Step 84000] loss = 0.3675 | acc = 0.8394 | grad_norm = 9.7343
2025-12-10 07:34:38,774 | [Step 84200] loss = 0.3690 | acc = 0.8413 | grad_norm = 26.7555
2025-12-10 07:38:22,515 | [Step 84400] loss = 0.3774 | acc = 0.8419 | grad_norm = 15.4335
2025-12-10 07:42:06,290 | [Step 84600] loss = 0.3718 | acc = 0.8213 | grad_norm = 12.7821
2025-12-10 07:45:49,940 | [Step 84800] loss = 0.3914 | acc = 0.8250 | grad_norm = 36.3341
2025-12-10 07:49:33,717 | [Step 85000] loss = 0.3560 | acc = 0.8381 | grad_norm = 13.8002
2025-12-10 07:53:17,412 | [Step 85200] loss = 0.3617 | acc = 0.8488 | grad_norm = 12.4628
2025-12-10 07:57:01,219 | [Step 85400] loss = 0.3679 | acc = 0.8363 | grad_norm = 10.5966
2025-12-10 08:00:44,862 | [Step 85600] loss = 0.3527 | acc = 0.8419 | grad_norm = 28.3333
2025-12-10 08:04:28,551 | [Step 85800] loss = 0.3845 | acc = 0.8306 | grad_norm = 25.2492
2025-12-10 08:08:12,267 | [Step 86000] loss = 0.3660 | acc = 0.8394 | grad_norm = 16.9887
2025-12-10 08:11:55,998 | [Step 86200] loss = 0.3570 | acc = 0.8419 | grad_norm = 20.4193
2025-12-10 08:15:39,733 | [Step 86400] loss = 0.3838 | acc = 0.8294 | grad_norm = 7.6024
2025-12-10 08:19:23,518 | [Step 86600] loss = 0.3536 | acc = 0.8419 | grad_norm = 27.5208
2025-12-10 08:23:07,307 | [Step 86800] loss = 0.3735 | acc = 0.8294 | grad_norm = 12.7438
2025-12-10 08:26:51,055 | [Step 87000] loss = 0.3368 | acc = 0.8531 | grad_norm = 11.2291
2025-12-10 08:30:34,749 | [Step 87200] loss = 0.3745 | acc = 0.8306 | grad_norm = 4.4487
2025-12-10 08:34:18,500 | [Step 87400] loss = 0.3908 | acc = 0.8256 | grad_norm = 26.5926
2025-12-10 08:38:02,196 | [Step 87600] loss = 0.3828 | acc = 0.8275 | grad_norm = 5.4514
2025-12-10 08:41:46,035 | [Step 87800] loss = 0.3657 | acc = 0.8350 | grad_norm = 46.1941
2025-12-10 08:45:29,855 | [Step 88000] loss = 0.3614 | acc = 0.8269 | grad_norm = 14.2849
2025-12-10 08:49:13,797 | [Step 88200] loss = 0.3689 | acc = 0.8344 | grad_norm = 20.3154
2025-12-10 08:52:57,666 | [Step 88400] loss = 0.3851 | acc = 0.8206 | grad_norm = 8.0432
2025-12-10 08:56:41,508 | [Step 88600] loss = 0.3561 | acc = 0.8294 | grad_norm = 21.2526
2025-12-10 09:00:25,322 | [Step 88800] loss = 0.3632 | acc = 0.8369 | grad_norm = 26.2255
2025-12-10 09:04:09,255 | [Step 89000] loss = 0.3477 | acc = 0.8369 | grad_norm = 25.3377
2025-12-10 09:07:53,162 | [Step 89200] loss = 0.3613 | acc = 0.8500 | grad_norm = 16.7376
2025-12-10 09:11:37,003 | [Step 89400] loss = 0.3617 | acc = 0.8394 | grad_norm = 17.7380
2025-12-10 09:15:20,970 | [Step 89600] loss = 0.3969 | acc = 0.8169 | grad_norm = 23.1564
2025-12-10 09:19:04,935 | [Step 89800] loss = 0.3545 | acc = 0.8394 | grad_norm = 13.3981
2025-12-10 09:22:48,978 | [Step 90000] loss = 0.3779 | acc = 0.8319 | grad_norm = 13.0928
2025-12-10 09:26:33,015 | [Step 90200] loss = 0.3742 | acc = 0.8331 | grad_norm = 12.9080
2025-12-10 09:30:17,143 | [Step 90400] loss = 0.3923 | acc = 0.8275 | grad_norm = 19.2565
2025-12-10 09:53:08,284 | [Epoch 5] Validation loss: 0.9264, Validation acc: 0.6323
2025-12-10 09:53:09,623 | Saved reward model to reward_model/gpt2_reward_model.pt
